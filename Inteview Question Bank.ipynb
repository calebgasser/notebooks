{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Interview Question Bank /w Answers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b28b56ebc069ece"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Machine Learning ðŸ¤–"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6743ed5bce405c53"
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Write a top-k sampling/nucleus sampling function for GPT in numpy\n",
    "2. Write the transformer layer with PyTorch\n",
    "3. Debug distributed numpy NN implementation\n",
    "4. Write a data processing pipeline with pandas/numpy\n",
    "5. Implement LR with numpy\n",
    "6. Implement a model from a white paper.. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92cc06d698d9577f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Write a top-k sampling/nucleus sampling function for GPT in numpy\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "465f1500d3033ff9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "First, what is a top-k sampling method? Here are some articles\n",
    "- [artical from hugging face](https://huggingface.co/blog/how-to-generate)\n",
    "- [The Large Language Model Playbook](https://cyrilzakka.github.io/llm-playbook/nested/topk.html)\n",
    "\n",
    "\n",
    "Here is what I got asking GPT-4 the question \"What is a top-k sampling method in regards to GPT?\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "93018ac393b5b37d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Top-k sampling is a technique used in text generation models like GPT (Generative Pre-trained Transformer) to produce more coherent and contextually relevant text. This method is a way to balance randomness and determinism in the text generation process. Here's a detailed explanation:\n",
    "\n",
    "1. **Understanding the Basics**:\n",
    "    - In text generation, the model predicts the next word in a sequence based on the probability distribution over the vocabulary given the current context (the words that have already been generated).\n",
    "    - This probability distribution is typically very broad, meaning many words could be potentially chosen as the next word, some of which might make sense and others which might not.\n",
    "\n",
    "2. **How Top-k Sampling Works**:\n",
    "    - Top-k sampling narrows down this choice. Instead of considering the entire vocabulary, it limits the possible next-word choices to the top 'k' most likely words as predicted by the model.\n",
    "    - 'k' is a parameter that you choose. A smaller 'k' makes the text generation less random (as fewer choices are considered) and a larger 'k' makes it more random.\n",
    "    - Once the top 'k' words are selected, one of them is randomly chosen based on their probability distribution. This word then becomes the next word in the generated text.\n",
    "\n",
    "3. **Benefits**:\n",
    "    - This method helps in reducing the randomness of the output by not considering highly improbable words, which leads to more coherent and contextually appropriate text.\n",
    "    - It also helps in avoiding the 'garbage text' problem, where the model might output nonsensical or irrelevant text, especially in longer sequences.\n",
    "\n",
    "4. **Drawbacks**:\n",
    "    - If 'k' is set too low, the model might become too deterministic and repetitive, as it will always choose among the most likely words.\n",
    "    - If 'k' is set too high, the model might still generate irrelevant or nonsensical text.\n",
    "\n",
    "5. **Comparison with Other Sampling Methods**:\n",
    "    - Top-k sampling is one approach among several used to control text generation. Another common method is 'temperature sampling', where the probability distribution is adjusted to control the randomness of the choice.\n",
    "    - There's also 'nucleus sampling' or 'top-p sampling', which is a more dynamic approach. Instead of choosing a fixed number of top candidates ('k'), it chooses the smallest set of words whose cumulative probability exceeds a threshold 'p'. This method adapts to the modelâ€™s confidence in its predictions.\n",
    "\n",
    "In summary, top-k sampling in GPT models is a technique to make the text generation process more controlled and relevant, by limiting the next-word choices to a subset of most probable words. It strikes a balance between creativity and coherence, which is crucial in applications like chatbots, story generation, and other natural language processing tasks."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab19c153eb78b079"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets break down the following implementation of top-k"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "67359f5e684081f3"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "def top_k_sampling(logits, k):\n",
    "    top_k_indices = np.argsort(logits)[-k:]  # Get indices of top-k logits\n",
    "    top_k_logits = logits[top_k_indices]  # Get the top-k logits\n",
    "    top_k_probs = np.exp(top_k_logits) / np.sum(np.exp(top_k_logits))  # Convert logits to probabilities\n",
    "    selected_index = np.random.choice(top_k_indices, p=top_k_probs)  # Sample from the top-k indices based on the probabilities\n",
    "    return selected_index"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T20:11:04.833906800Z",
     "start_time": "2024-01-14T20:11:04.817013700Z"
    }
   },
   "id": "cb91b7c56d3a5b2b",
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "source": [
    "The arguments are `logits` and `k`, where `k` is the number of choices to choose from. What are the `logits` though?\n",
    "Logits are the raw, un-normalized output of the last layer of a neural network which can be any number in $\\mathbb{R}$.\n",
    "Logits are before any activation function (like softmax) is applied. This function is to transform the logits into a more interpretable from, often probabilites.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77c3f4c4b19865b3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "`top_k_indices = np.argsort(logits)[-k:]`\n",
    "Here we are getting the indices for the top-k arguments. First lets understand the function `argsort`. This is [from the documentation](https://numpy.org/doc/stable/reference/generated/numpy.argsort.html)\n",
    "```\n",
    "numpy.argsort(a, axis=-1, kind=None, order=None)\n",
    "    Returns the indices that would sort an array.\n",
    "\n",
    "    Perform an indirect sort along the given axis using the algorithm specified by the kind keyword. It returns an array of indices of the same shape as a that index data along the given axis in sorted order.\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d52882b716a1e265"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lets see what argsort is doing."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26bf2c8fa9f1252c"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([-25.09197623,  90.14286128,  46.39878836,  19.73169684,\n       -68.79627191, -68.80109593, -88.38327757,  73.23522915,\n        20.22300235,  41.61451556])"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "array([6, 5, 4, 0, 3, 8, 9, 2, 7, 1], dtype=int64)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_logits = np.random.uniform(-100.0, 100.0, (10,))\n",
    "display(random_logits)\n",
    "list_indicies = np.argsort(random_logits)\n",
    "list_indicies"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T20:11:04.843952800Z",
     "start_time": "2024-01-14T20:11:04.836911200Z"
    }
   },
   "id": "527eca5300defad0",
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here is an example of what the `[-k:]` is doing, which is grabbing the last `k` elements of the list. Since the indices are sorted, the last 3 elements are the ones with the heights value."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14f136f7d3bb006d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([2, 7, 1], dtype=int64)"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_indicies = list_indicies[-3:]\n",
    "list_indicies"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T20:11:04.863231800Z",
     "start_time": "2024-01-14T20:11:04.840948800Z"
    }
   },
   "id": "e799b5d0ac85f874",
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "source": [
    "Get the top `k` logits"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b55351fab2534602"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([46.39878836, 73.23522915, 90.14286128])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_random_logits = random_logits[list_indicies]\n",
    "top_k_random_logits"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T20:11:04.863231800Z",
     "start_time": "2024-01-14T20:11:04.847832700Z"
    }
   },
   "id": "97e3b0760410a5f9",
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we convert the logits to probabilities."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8d44ed686d32c36"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array([1.00505654e-19, 4.54055191e-08, 9.99999955e-01])"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_probs = np.exp(top_k_random_logits) / np.sum(np.exp(top_k_random_logits))\n",
    "top_k_probs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T20:11:04.863231800Z",
     "start_time": "2024-01-14T20:11:04.855227Z"
    }
   },
   "id": "fc7b3bd0db4b4809",
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Index: 1\n",
      "Selected value: 90.14286128198324\n"
     ]
    }
   ],
   "source": [
    "selected_index = np.random.choice(list_indicies, p=top_k_probs)\n",
    "print(f\"Selected Index: {selected_index}\")\n",
    "print(f\"Selected value: {random_logits[selected_index]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T20:11:04.870109700Z",
     "start_time": "2024-01-14T20:11:04.864235500Z"
    }
   },
   "id": "7c6071248e0a5911",
   "execution_count": 55
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Write the transformer layer with PyTorch\n",
    "---"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eaeae4fdd637accf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T20:11:04.872283700Z",
     "start_time": "2024-01-14T20:11:04.871780600Z"
    }
   },
   "id": "64f3c4c690c42571",
   "execution_count": 55
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
